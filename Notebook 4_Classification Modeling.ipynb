{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Classification-Modeling\" data-toc-modified-id=\"Classification-Modeling-1\">Classification Modeling</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Import-Libraries\" data-toc-modified-id=\"Import-Libraries-1.0.0.1\">Import Libraries</a></span></li></ul></li></ul></li><li><span><a href=\"#Model-Prep\" data-toc-modified-id=\"Model-Prep-1.1\">Model Prep</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Step-1:-Choose-features.\" data-toc-modified-id=\"Step-1:-Choose-features.-1.1.0.1\">Step 1: Choose features.</a></span></li><li><span><a href=\"#Step-2:-Train/Test-Split\" data-toc-modified-id=\"Step-2:-Train/Test-Split-1.1.0.2\">Step 2: Train/Test Split</a></span></li><li><span><a href=\"#Step-3:-Baseline-Accuracy-Score\" data-toc-modified-id=\"Step-3:-Baseline-Accuracy-Score-1.1.0.3\">Step 3: Baseline Accuracy Score</a></span></li></ul></li></ul></li></ul></li><li><span><a href=\"#Models-w/-CountVectorizer\" data-toc-modified-id=\"Models-w/-CountVectorizer-2\">Models w/ CountVectorizer</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Pipeline\" data-toc-modified-id=\"Pipeline-2.0.0.1\">Pipeline</a></span></li><li><span><a href=\"#GridSearchCV\" data-toc-modified-id=\"GridSearchCV-2.0.0.2\">GridSearchCV</a></span></li></ul></li></ul></li><li><span><a href=\"#Model-Scores\" data-toc-modified-id=\"Model-Scores-2.1\">Model Scores</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Logistic-Regression\" data-toc-modified-id=\"Logistic-Regression-2.1.0.1\">Logistic Regression</a></span></li><li><span><a href=\"#Multinomial-Naive-Bayes\" data-toc-modified-id=\"Multinomial-Naive-Bayes-2.1.0.2\">Multinomial Naive Bayes</a></span></li></ul></li></ul></li></ul></li><li><span><a href=\"#Models-w/-TfidfVectorizer\" data-toc-modified-id=\"Models-w/-TfidfVectorizer-3\">Models w/ TfidfVectorizer</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Pipeline\" data-toc-modified-id=\"Pipeline-3.0.0.1\">Pipeline</a></span></li><li><span><a href=\"#GridSearchCV\" data-toc-modified-id=\"GridSearchCV-3.0.0.2\">GridSearchCV</a></span></li></ul></li></ul></li><li><span><a href=\"#Model-Scores\" data-toc-modified-id=\"Model-Scores-3.1\">Model Scores</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Logistic-Regression\" data-toc-modified-id=\"Logistic-Regression-3.1.0.1\">Logistic Regression</a></span></li><li><span><a href=\"#Multinomial-Naive-Bayes\" data-toc-modified-id=\"Multinomial-Naive-Bayes-3.1.0.2\">Multinomial Naive Bayes</a></span></li></ul></li></ul></li></ul></li><li><span><a href=\"#Evaluation-of-Models\" data-toc-modified-id=\"Evaluation-of-Models-4\">Evaluation of Models</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intro to Notebook 4 \n",
    "\n",
    "This notebook (Notebook 4) will focus on fine tuning features to train classification models with the intent of identifying strong predictors and score high in accuracy. \n",
    "<br>\n",
    "<br>\n",
    "The classification models that will be used are: \n",
    "1. Logistic regression\n",
    "2. Multinomial Naive Bayes\n",
    "\n",
    "\n",
    "The Logistic regression model will have two possible outputs. In this case, it is to predict 0(r/Dreams) or 1(r/schizophrenia). It can be used when the dependent variable(target) is categorical and can explain the relationship between one dependent binary variable to one independent variable. Because of these reasons and more, this was a good model to use for this project's proposed goal to predict whether a post should be in either r/Dreams or r/schizophrenia.\n",
    "\n",
    "The Multinomial Naive Bayes model estimates the conditional probability of a tag given its relative frequency for a given text and then outputs the tag with the highest one. When considering text analysis, the model is \"naive\" because it assumes that every word is independent from the other ones. For example, \"this was a vivid dream\" , \"this dream was vivid\" and \"vivid dream is this\" would all be considered the same. Moreover, this model is great in working with little data and/or data that's mislabeled. So, knowing that the data may not be thoroughly cleaned for spelling errors/mislabels as well as given the overall subjects/context being analyzed are not known to always have grammatically correct language, this is a good model to try out.\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "This notebook is structured with the following terms...\n",
    "- <b>Observations</b> : comments on previously printed lines of code. \n",
    "- <b>Purpose of the following code</b> : explanation/reason for upcoming lines of code. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(60000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 60 seconds\n"
     ]
    }
   ],
   "source": [
    "# For scientific computing  \n",
    "import numpy as np\n",
    "# For plotting, data manipulation, data analysis\n",
    "import pandas as pd\n",
    "# For plotting visualization\n",
    "import seaborn as sns\n",
    "# For plotting visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use('fivethirtyeight')\n",
    "                                         # Module with score functions, perforamnce computations, etc\n",
    "from sklearn                             import metrics\n",
    "                                         # Function computes subset accuracy\n",
    "                                         # Evaluate the accuracy of a classification\n",
    "                                         # Outputs weighted average of precision and recall\n",
    "from sklearn.metrics                     import accuracy_score, confusion_matrix, f1_score                         \n",
    "                                         # Naive Bayes classifier is suitable for discrete features\n",
    "from sklearn.naive_bayes                 import MultinomialNB\n",
    "                                         # Apply a list of transforms and a final estimator\n",
    "                                         # Construct pipeline from given estimators\n",
    "from sklearn.pipeline                    import Pipeline, make_pipeline\n",
    "                                         # Convert text to word count vectors (CountVect)\n",
    "                                         # Convert text to word frequency vectors (Tfidf)\n",
    "from sklearn.feature_extraction.text     import CountVectorizer, TfidfVectorizer\n",
    "                                         # Base class for all estimators in scikit-learn\n",
    "                                         # Mixin class for all classifiers in scikit-learn\n",
    "from sklearn.base                        import BaseEstimator, ClassifierMixin\n",
    "                                         # Classifier\n",
    "from sklearn.linear_model                import LogisticRegression\n",
    "                                         # Splits dataset into a train set and a test set\n",
    "                                         # Evaluate a score by cross validation\n",
    "                                         # Search over specified parameter values for an estimator\n",
    "from sklearn.model_selection             import train_test_split, cross_val_score, GridSearchCV\n",
    "                                         # API for NLP tasks \n",
    "from textblob                            import TextBlob, Word\n",
    "                                         # Plots adjust colors to accomodate dark jupyter theme\n",
    "from jupyterthemes                       import jtplot\n",
    "jtplot.style(theme= 'gruvboxd', context='notebook', ticks=True, grid=False)\n",
    "                                         # Can use as baseline for to compare other regressors\n",
    "from sklearn.dummy                       import DummyRegressor, DummyClassifier\n",
    "\n",
    "# Displays up to 200 rows when using functions\n",
    "pd.options.display.max_rows = 200\n",
    "# Displays up to 200 columns when using functions\n",
    "pd.options.display.max_columns = 200\n",
    "\n",
    "# For plotting\n",
    "%matplotlib inline\n",
    "# Makes plots look better (resolution)\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "# Automatically saves notebook every 60 seconds\n",
    "%autosave 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuts off FutureWarning being printed \n",
    "import warnings\n",
    "# FutureWarning is a base category for warnings on future constructs that will change semantically.\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in cleaned combo of dreams and schizophrenia subreddits dataset from Notebook 3\n",
    "cleaned_subreddits = pd.read_csv('./cleaned_subreddits.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>body</th>\n",
       "      <th>subreddit_label</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Just dreamt of the end of the world</td>\n",
       "      <td>Dreams</td>\n",
       "      <td>I just woke from an insanely realistic dream a...</td>\n",
       "      <td>0</td>\n",
       "      <td>dreamt end world woke insanely realistic dream...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>I was accused of blugeoning Beyonce to death i...</td>\n",
       "      <td>Dreams</td>\n",
       "      <td>I was in my local Kroger getting groceries, an...</td>\n",
       "      <td>0</td>\n",
       "      <td>accused blugeoning beyonce death kroger local ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Morgan Freeman food advice</td>\n",
       "      <td>Dreams</td>\n",
       "      <td>Part of my dream this morning had Morgan Freem...</td>\n",
       "      <td>0</td>\n",
       "      <td>morgan freeman food advice part dream morning ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Violating the nightmare</td>\n",
       "      <td>Dreams</td>\n",
       "      <td>Well uh.. where to begin...\\n\\nI found this su...</td>\n",
       "      <td>0</td>\n",
       "      <td>violating nightmare well uh begin found sub go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>Dreamt was holding my rapist and crying and ap...</td>\n",
       "      <td>Dreams</td>\n",
       "      <td>I don't understand.. I was finally getting bet...</td>\n",
       "      <td>0</td>\n",
       "      <td>dreamt holding rapist cry apologizing making l...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                              title subreddit  \\\n",
       "0           0                Just dreamt of the end of the world    Dreams   \n",
       "1           1  I was accused of blugeoning Beyonce to death i...    Dreams   \n",
       "2           2                         Morgan Freeman food advice    Dreams   \n",
       "3           3                            Violating the nightmare    Dreams   \n",
       "4           4  Dreamt was holding my rapist and crying and ap...    Dreams   \n",
       "\n",
       "                                                body  subreddit_label  \\\n",
       "0  I just woke from an insanely realistic dream a...                0   \n",
       "1  I was in my local Kroger getting groceries, an...                0   \n",
       "2  Part of my dream this morning had Morgan Freem...                0   \n",
       "3  Well uh.. where to begin...\\n\\nI found this su...                0   \n",
       "4  I don't understand.. I was finally getting bet...                0   \n",
       "\n",
       "                                             content  \n",
       "0  dreamt end world woke insanely realistic dream...  \n",
       "1  accused blugeoning beyonce death kroger local ...  \n",
       "2  morgan freeman food advice part dream morning ...  \n",
       "3  violating nightmare well uh begin found sub go...  \n",
       "4  dreamt holding rapist cry apologizing making l...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at values of columns and rows in dataset\n",
    "cleaned_subreddits.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observations: \n",
    "- There's an 'Unnamed: 0' column.\n",
    "- Because the values of 'title' and 'body' have been combined to make 'content' column, 'content' column seems to be the best feature with text to input models with. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Purpose of code: 'Unnamed:0' column needs to be dropped and index reset as it offers no valuable insight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Unnamed: 0 column \n",
    "cleaned_subreddits.drop(cleaned_subreddits[['Unnamed: 0']].columns, axis = 1, inplace=True)\n",
    "# Reset index\n",
    "cleaned_subreddits.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>body</th>\n",
       "      <th>subreddit_label</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Just dreamt of the end of the world</td>\n",
       "      <td>Dreams</td>\n",
       "      <td>I just woke from an insanely realistic dream a...</td>\n",
       "      <td>0</td>\n",
       "      <td>dreamt end world woke insanely realistic dream...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>I was accused of blugeoning Beyonce to death i...</td>\n",
       "      <td>Dreams</td>\n",
       "      <td>I was in my local Kroger getting groceries, an...</td>\n",
       "      <td>0</td>\n",
       "      <td>accused blugeoning beyonce death kroger local ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Morgan Freeman food advice</td>\n",
       "      <td>Dreams</td>\n",
       "      <td>Part of my dream this morning had Morgan Freem...</td>\n",
       "      <td>0</td>\n",
       "      <td>morgan freeman food advice part dream morning ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Violating the nightmare</td>\n",
       "      <td>Dreams</td>\n",
       "      <td>Well uh.. where to begin...\\n\\nI found this su...</td>\n",
       "      <td>0</td>\n",
       "      <td>violating nightmare well uh begin found sub go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Dreamt was holding my rapist and crying and ap...</td>\n",
       "      <td>Dreams</td>\n",
       "      <td>I don't understand.. I was finally getting bet...</td>\n",
       "      <td>0</td>\n",
       "      <td>dreamt holding rapist cry apologizing making l...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title subreddit  \\\n",
       "0                Just dreamt of the end of the world    Dreams   \n",
       "1  I was accused of blugeoning Beyonce to death i...    Dreams   \n",
       "2                         Morgan Freeman food advice    Dreams   \n",
       "3                            Violating the nightmare    Dreams   \n",
       "4  Dreamt was holding my rapist and crying and ap...    Dreams   \n",
       "\n",
       "                                                body  subreddit_label  \\\n",
       "0  I just woke from an insanely realistic dream a...                0   \n",
       "1  I was in my local Kroger getting groceries, an...                0   \n",
       "2  Part of my dream this morning had Morgan Freem...                0   \n",
       "3  Well uh.. where to begin...\\n\\nI found this su...                0   \n",
       "4  I don't understand.. I was finally getting bet...                0   \n",
       "\n",
       "                                             content  \n",
       "0  dreamt end world woke insanely realistic dream...  \n",
       "1  accused blugeoning beyonce death kroger local ...  \n",
       "2  morgan freeman food advice part dream morning ...  \n",
       "3  violating nightmare well uh begin found sub go...  \n",
       "4  dreamt holding rapist cry apologizing making l...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print to double check Unnamed column was successfully dropped and index reset\n",
    "cleaned_subreddits.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observations: Yay! 'Unnamed: 0' column dropped and index successfully reset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Prep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: Choose features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Purpose of code: Because only two columns are being chosen for this model prep, and the option to switch or add other features later should be left open, it's best to create a separate dataframe with the features about to be used so as to avoid affecting the cleaned_subreddits dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit_label</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>dreamt end world woke insanely realistic dream...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>accused blugeoning beyonce death kroger local ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>morgan freeman food advice part dream morning ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>violating nightmare well uh begin found sub go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>dreamt holding rapist cry apologizing making l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1990</td>\n",
       "      <td>1</td>\n",
       "      <td>side effect antipchycotics two week ago inject...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1991</td>\n",
       "      <td>1</td>\n",
       "      <td>study ppl quit med long use big brother stoppe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1992</td>\n",
       "      <td>1</td>\n",
       "      <td>spider man far home mega triggering got halfwa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1993</td>\n",
       "      <td>1</td>\n",
       "      <td>supporting fiancé support fiancé paranoid delu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1994</td>\n",
       "      <td>1</td>\n",
       "      <td>another reality know know another reality one ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1995 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      subreddit_label                                            content\n",
       "0                   0  dreamt end world woke insanely realistic dream...\n",
       "1                   0  accused blugeoning beyonce death kroger local ...\n",
       "2                   0  morgan freeman food advice part dream morning ...\n",
       "3                   0  violating nightmare well uh begin found sub go...\n",
       "4                   0  dreamt holding rapist cry apologizing making l...\n",
       "...               ...                                                ...\n",
       "1990                1  side effect antipchycotics two week ago inject...\n",
       "1991                1  study ppl quit med long use big brother stoppe...\n",
       "1992                1  spider man far home mega triggering got halfwa...\n",
       "1993                1  supporting fiancé support fiancé paranoid delu...\n",
       "1994                1  another reality know know another reality one ...\n",
       "\n",
       "[1995 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create dataframe with only subreddit_label and content columns\n",
    "model_subreddits = cleaned_subreddits.loc[:, ['subreddit_label', 'content']]\n",
    "# Print new dataframe to double check the columns were successfully captured \n",
    "model_subreddits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observations:\n",
    "- New dataframe successfully captured subreddit_label and content columns. \n",
    "- New dataframe has 1995 rows and 2 columns which is perfect for the logistic regression model about to be fitted. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define X and y\n",
    "X = model_subreddits['content']\n",
    "# y is what model will eventually attempt to predict\n",
    "y = model_subreddits['subreddit_label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Purpose of code: It's important to split data into train set and test set so that the model can learn on the train set then use the test set to test model's prediction/how well model was trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data to training and testing sets with test_size 30% and training 70%\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size=0.30,\n",
    "                                                    stratify=y,\n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3: Baseline Accuracy Score\n",
    "This is neccesary to calculate prior to diving into modeling as the score will be used to tell if model is outperforming the null model in predicting if a if post goes to subreddit \"0: Dreams\" or \"1: schizophrenia\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.500716\n",
       "0    0.499284\n",
       "Name: subreddit_label, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print baseline for train data\n",
    "y_train.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.500835\n",
       "0    0.499165\n",
       "Name: subreddit_label, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print baseline for test data\n",
    "y_test.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models w/ CountVectorizer\n",
    "<b>CountVectorizer</b>\n",
    "<br>\n",
    "<br>\n",
    "CountVectorizer provides will tokenize a collection of text documents and build a vocabulary of known words. This is helpful for the type of models being built here as CountVectorizer will take out the words that would likely inaccurately skew the results and/or words that do not offer much insight as to defining the distinction between the two subreddits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Purpose of code: Add custom stopwords to CountVectorizer. While custom stopwords were added during EDA in Notebook 3, the words were added into a separate dataset which was only to be used for EDA. It was best to not permanently add the custom stopwords to cleaned_subreddits dataset in case there were desired changes to be made after assessing results of EDA. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "stops = ['schizophrenia',\n",
    "         'schizophreniacs',\n",
    "         'dream', \n",
    "         'dreams', \n",
    "         'really', \n",
    "         'get', \n",
    "         'thing', \n",
    "         'reddit', \n",
    "         'www', \n",
    "         'com']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Purpose of code: Set up pipeline so as to help in reproducibility and overall make a fluid workflow. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('cvec',\n",
       "                 CountVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                 input='content', lowercase=True, max_df=1.0,\n",
       "                                 max_features=None, min_df=1,\n",
       "                                 ngram_range=(1, 1), preprocessor=None,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, vocabulary=None)),\n",
       "                ('mb',\n",
       "                 MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set up pipeline for CountVectorizer LogisticRegression\n",
    "lr_pipe = Pipeline([\n",
    " ('cvec', CountVectorizer()),\n",
    " ('lr', LogisticRegression())\n",
    "])\n",
    "\n",
    "# Set up pipeline for CountVectorizer Multinomial\n",
    "mb_pipe = Pipeline([\n",
    " ('cvec', CountVectorizer()),\n",
    " ('mb', MultinomialNB())\n",
    "])\n",
    "\n",
    "# Fit LogisticRegression pipeline\n",
    "lr_pipe.fit(X_train, y_train)\n",
    "# Fit MultinomialNB pipeline\n",
    "mb_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set params for CountVectorizer GridsearchCV\n",
    "pipe_params = {\n",
    "    # Maximum number of features fit: 2500, 3500 for cvec\n",
    "    'cvec__max_features': [2500, 3500],\n",
    "    # Minimum number of documents needed to include token: 2, 3 for cvec\n",
    "    'cvec__min_df': [2, 3],\n",
    "    # Ignore terms that appear in more than 90% of the documents, in more than 95 documents\n",
    "    'cvec__max_df': [.9, .95],\n",
    "    # Use unigram and bigrams and then have it pick which one is optimal for cvec\n",
    "    'cvec__ngram_range': [(1,1), (2,2)],\n",
    "    'cvec__stop_words': [stops, 'english']\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GridSearchCV\n",
    "- Pass pipeline through with the parameters that were set above.\n",
    "- Run standard cross-validation on model with a fold of 3. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Purpose of code: The optimal hyperparameters need to be found of a models so as to result in the most accurate predictions. So, GridSearchCV is used for Logistic Regression then MultinomialNB. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('cvec',\n",
       "                                        CountVectorizer(analyzer='word',\n",
       "                                                        binary=False,\n",
       "                                                        decode_error='strict',\n",
       "                                                        dtype=<class 'numpy.int64'>,\n",
       "                                                        encoding='utf-8',\n",
       "                                                        input='content',\n",
       "                                                        lowercase=True,\n",
       "                                                        max_df=1.0,\n",
       "                                                        max_features=None,\n",
       "                                                        min_df=1,\n",
       "                                                        ngram_range=(1, 1),\n",
       "                                                        preprocessor=None,\n",
       "                                                        stop_words=None,\n",
       "                                                        strip_accents=None,\n",
       "                                                        tok...\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'cvec__max_df': [0.9, 0.95],\n",
       "                         'cvec__max_features': [2500, 3500],\n",
       "                         'cvec__min_df': [2, 3],\n",
       "                         'cvec__ngram_range': [(1, 1), (2, 2)],\n",
       "                         'cvec__stop_words': [['schizophrenia',\n",
       "                                               'schizophreniacs', 'dream',\n",
       "                                               'dreams', 'really', 'get',\n",
       "                                               'thing', 'reddit', 'www',\n",
       "                                               'com'],\n",
       "                                              'english']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set up GridSearchCV for LogisticRegression\n",
    "lr_gs = GridSearchCV(lr_pipe, \n",
    "                  # The parameter values that will be searched\n",
    "                  param_grid = pipe_params,\n",
    "                  # 3-fold cross-validation\n",
    "                  cv = 3) \n",
    "\n",
    "# Fit LogisticRegression GridSearchCV\n",
    "lr_gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('cvec',\n",
       "                                        CountVectorizer(analyzer='word',\n",
       "                                                        binary=False,\n",
       "                                                        decode_error='strict',\n",
       "                                                        dtype=<class 'numpy.int64'>,\n",
       "                                                        encoding='utf-8',\n",
       "                                                        input='content',\n",
       "                                                        lowercase=True,\n",
       "                                                        max_df=1.0,\n",
       "                                                        max_features=None,\n",
       "                                                        min_df=1,\n",
       "                                                        ngram_range=(1, 1),\n",
       "                                                        preprocessor=None,\n",
       "                                                        stop_words=None,\n",
       "                                                        strip_accents=None,\n",
       "                                                        tok...\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'cvec__max_df': [0.9, 0.95],\n",
       "                         'cvec__max_features': [2500, 3500],\n",
       "                         'cvec__min_df': [2, 3],\n",
       "                         'cvec__ngram_range': [(1, 1), (2, 2)],\n",
       "                         'cvec__stop_words': [['schizophrenia',\n",
       "                                               'schizophreniacs', 'dream',\n",
       "                                               'dreams', 'really', 'get',\n",
       "                                               'thing', 'reddit', 'www',\n",
       "                                               'com'],\n",
       "                                              'english']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set up GridSearchCV for MultinomialNB\n",
    "mb_gs = GridSearchCV(mb_pipe, \n",
    "                  # The parameter values that will be searched\n",
    "                  param_grid = pipe_params,\n",
    "                  # 3-fold cross-validation\n",
    "                  cv = 3) \n",
    "\n",
    "# Fit MultinomialNB GridSearchCV\n",
    "mb_gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Scores\n",
    "Models with CountVectorizer have been fit now it's time to score models on both the train data and the test data. \n",
    "<br>\n",
    "The scores are calculated as such:\n",
    "- .score with predictor: compares the y-hat(predicated value) against y to give a measure for accuracy.\n",
    "\n",
    "- .score with (X_train, y_train): measures the accuracy of model against the train data. This means how well the model was trained. \n",
    "\n",
    "- .score with (X_test, y_test): equivalent to .score with predictor, but y_pred doesn't get calculate- since the library does that internally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make class prediction and probability for the train data LogisticRegression\n",
    "lr_y_pred = lr_gs.predict(X_test)\n",
    "\n",
    "# Make class prediction and probability for the test data MultinomialNB\n",
    "mb_y_pred = mb_gs.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Purpose of code: We want to compare the performance of two classifiers so use f1_score. Ultimately, this means, when model predicts, how often is it correct.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score: 0.954248\n",
      "F1 score: 0.940375\n"
     ]
    }
   ],
   "source": [
    "# Print f1_score: 2 TP / (2 TP + FP + FN)\n",
    "f1_logr = f1_score(y_test, lr_y_pred)\n",
    "print('F1 score: %f' % f1_logr)\n",
    "\n",
    "f1_multiNB = f1_score(y_test, mb_y_pred)\n",
    "print('F1 score: %f' % f1_multiNB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observations: Awesome! The F1 scores are high and means precision and recall of model indicates good results. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.953\n",
      "Train score: 0.989\n",
      "Test score: 0.953\n"
     ]
    }
   ],
   "source": [
    "# Print accuracy score for LogisticRegression. \n",
    "lr_score = accuracy_score(y_test, lr_y_pred)\n",
    "# Accuracy= (TP + TN) / all\n",
    "print(\"Accuracy: {:.3f}\".format(lr_score))\n",
    "# Print best score train set\n",
    "print(\"Train score: {:.3f}\".format(lr_gs.score(X_train, y_train)))\n",
    "# Print best score test set\n",
    "print(\"Test score: {:.3f}\".format(lr_gs.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best cross-validation score: 0.989\n"
     ]
    }
   ],
   "source": [
    "# Scoring train data on LogisticRegression\n",
    "lr_train_score = lr_gs.score(X_train, y_train)\n",
    "print(\"Best cross-validation score: {:.3f}\".format(lr_gs.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "[[279  20]\n",
      " [  8 292]]\n",
      "\n",
      "---------------\n",
      "[['TN' 'FP']\n",
      " ['FN' 'TP']]\n"
     ]
    }
   ],
   "source": [
    "# Print confusion matrix for Logistic Regression model\n",
    "lr_cfm = confusion_matrix(y_test, lr_y_pred)\n",
    "print(\"Confusion matrix:\")\n",
    "print(lr_cfm, end='\\n\\n')\n",
    "print('-'*15)\n",
    "# Print [True Negative, False Positive] [False Negative, True Positive]\n",
    "print(np.array([['TN', 'FP'],[ 'FN' , 'TP']]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.942\n",
      "Train score: 0.961\n",
      "Test score: 0.942\n"
     ]
    }
   ],
   "source": [
    "# Print accuracy score for MultinomialNB\n",
    "mb_score = accuracy_score(y_test, mb_y_pred)\n",
    "# Accuracy= (tp + tn) / all\n",
    "print(\"Accuracy: {:.3f}\".format(mb_score))\n",
    "# Print best score train set\n",
    "print(\"Train score: {:.3f}\".format(mb_gs.score(X_train, y_train)))\n",
    "# Print best score test set\n",
    "print(\"Test score: {:.3f}\".format(mb_gs.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best cross-validation score: 0.961\n"
     ]
    }
   ],
   "source": [
    "# Score for test data on MultinomialNB\n",
    "print(\"Best cross-validation score: {:.3f}\".format(mb_gs.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "[[288  11]\n",
      " [ 24 276]]\n",
      "\n",
      "---------------\n",
      "[['TN' 'FP']\n",
      " ['FN' 'TP']]\n"
     ]
    }
   ],
   "source": [
    "# Print confusion matrix for MultinomialNB model\n",
    "mb_cfm = confusion_matrix(y_test, mb_y_pred)\n",
    "print(\"Confusion matrix:\")\n",
    "print(mb_cfm, end='\\n\\n')\n",
    "print('-'*15)\n",
    "# Print [True Negative, False Positive] [False Negative, True Positive]\n",
    "print(np.array([['TN', 'FP'],[ 'FN' , 'TP']]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observations: Yay! False Positives and False Negatives are low which is a great indicator in further reaffirming and visually cementing that model is great at predicting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models w/ TfidfVectorizer\n",
    "<b>Term Frequency-Inverse Document Frequency (TF-IDF)</b>\n",
    "<br>\n",
    "<br>\n",
    "Stopwords aren't assigned to TFDIF as TFDIF assigns weights to the most frequent words and least frequency words used.\n",
    "\n",
    "Given CountVectorizer was initially used with the Logistic Regression Model(above), using TF-IDF with Logistic Regression Model may output different results and be a good comparison to whether CountVectorizer betters the model's performance more than TF-IDF. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Purpose of code: Set up pipeline so as to help in reproducibility and overall make a fluid workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate TfidfVectorizer\n",
    "tvec = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('tvec',\n",
       "                 TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.float64'>,\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=True, max_df=1.0, max_features=None,\n",
       "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
       "                                 preprocessor=None, smooth_idf=True,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 sublinear_tf=False,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, use_idf=True,\n",
       "                                 vocabulary=None)),\n",
       "                ('mb',\n",
       "                 MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set up pipline for TfidfVectorizer LogisticRegression\n",
    "lr_tvec_pipe = Pipeline([\n",
    "    ('tvec', TfidfVectorizer()),\n",
    "    ('lr', LogisticRegression())\n",
    "])\n",
    "\n",
    "\n",
    "# Set up pipeline for TfidfVectorizer MultinomialNB\n",
    "mb_tvec_pipe = Pipeline([\n",
    " ('tvec', TfidfVectorizer()),\n",
    " ('mb', MultinomialNB())\n",
    "])\n",
    "\n",
    "# Fit LogisticRegression pipeline\n",
    "lr_tvec_pipe.fit(X_train, y_train)\n",
    "# Fit MultinomialNB pipeline\n",
    "mb_tvec_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set params for TfdifVectorizer GridsearchCV\n",
    "pipe_params = {\n",
    "    # Maximum number of features fit: 2500, 3500 for cvec\n",
    "    'tvec__max_features': [2500, 3500],\n",
    "    # Minimum number of documents needed to include token: 2, 3 for cvec\n",
    "    'tvec__min_df': [2, 3],\n",
    "    # Ignore terms that appear in more than 90% of the documents, in more than 95 documents\n",
    "    'tvec__max_df': [.9, .95],\n",
    "    # Use unigram and bigrams and then have it pick which one is optimal for cvec\n",
    "    'tvec__ngram_range': [(1,1), (2,2)],\n",
    "    'tvec__stop_words': [stops, 'english']\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GridSearchCV\n",
    "- Pass pipeline through with the parameters that were set above.\n",
    "- Run standard cross-validation on model with a fold of 3. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Purpose of code: The optimal hyperparameters need to be found of a models so as to result in the most accurate predictions. So, GridSearchCV is used for Logistic Regression then MultinomialNB. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('tvec',\n",
       "                                        TfidfVectorizer(analyzer='word',\n",
       "                                                        binary=False,\n",
       "                                                        decode_error='strict',\n",
       "                                                        dtype=<class 'numpy.float64'>,\n",
       "                                                        encoding='utf-8',\n",
       "                                                        input='content',\n",
       "                                                        lowercase=True,\n",
       "                                                        max_df=1.0,\n",
       "                                                        max_features=None,\n",
       "                                                        min_df=1,\n",
       "                                                        ngram_range=(1, 1),\n",
       "                                                        norm='l2',\n",
       "                                                        preprocessor=None,\n",
       "                                                        smooth_idf=True,\n",
       "                                                        stop_words...\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'tvec__max_df': [0.9, 0.95],\n",
       "                         'tvec__max_features': [2500, 3500],\n",
       "                         'tvec__min_df': [2, 3],\n",
       "                         'tvec__ngram_range': [(1, 1), (2, 2)],\n",
       "                         'tvec__stop_words': [['schizophrenia',\n",
       "                                               'schizophreniacs', 'dream',\n",
       "                                               'dreams', 'really', 'get',\n",
       "                                               'thing', 'reddit', 'www',\n",
       "                                               'com'],\n",
       "                                              'english']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set up GridSearchCV for LogisticRegression\n",
    "lr_tvec_gs = GridSearchCV(lr_tvec_pipe, \n",
    "                  # The parameter values that will be searched\n",
    "                  param_grid = pipe_params,\n",
    "                  # 3-fold cross-validation\n",
    "                  cv = 3) \n",
    "\n",
    "# Fit LogisticRegression GridSearchCV\n",
    "lr_tvec_gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('tvec',\n",
       "                                        TfidfVectorizer(analyzer='word',\n",
       "                                                        binary=False,\n",
       "                                                        decode_error='strict',\n",
       "                                                        dtype=<class 'numpy.float64'>,\n",
       "                                                        encoding='utf-8',\n",
       "                                                        input='content',\n",
       "                                                        lowercase=True,\n",
       "                                                        max_df=1.0,\n",
       "                                                        max_features=None,\n",
       "                                                        min_df=1,\n",
       "                                                        ngram_range=(1, 1),\n",
       "                                                        norm='l2',\n",
       "                                                        preprocessor=None,\n",
       "                                                        smooth_idf=True,\n",
       "                                                        stop_words...\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'tvec__max_df': [0.9, 0.95],\n",
       "                         'tvec__max_features': [2500, 3500],\n",
       "                         'tvec__min_df': [2, 3],\n",
       "                         'tvec__ngram_range': [(1, 1), (2, 2)],\n",
       "                         'tvec__stop_words': [['schizophrenia',\n",
       "                                               'schizophreniacs', 'dream',\n",
       "                                               'dreams', 'really', 'get',\n",
       "                                               'thing', 'reddit', 'www',\n",
       "                                               'com'],\n",
       "                                              'english']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set up GridSearchCV for MultinomialNB\n",
    "mb_tvec_gs = GridSearchCV(mb_tvec_pipe, \n",
    "                  # The parameter values that will be searched\n",
    "                  param_grid = pipe_params,\n",
    "                  # 3-fold cross-validation\n",
    "                  cv = 3) \n",
    "\n",
    "# Fit MultinomialNB GridSearchCV\n",
    "mb_tvec_gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Scores\n",
    "Models with TfidfVectorizer have been fit now it's time to score models on both the train data and the test data. \n",
    "<br>\n",
    "The scores are calculated as such:\n",
    "- .score with predictor: compares the y-hat(predicated value) against y to give a measure for accuracy.\n",
    "\n",
    "- .score with (X_train, y_train): measures the accuracy of model against the train data. This means how well the model was trained. \n",
    "\n",
    "- .score with (X_test, y_test): equivalent to .score with predictor, but y_pred doesn't get calculate- since the library does that internally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make class and probability predictions for the test set LogisticRegression\n",
    "logr_y_pred = lr_tvec_gs.predict(X_test)\n",
    "\n",
    "# Make class predictions for the test set MultinomialNB\n",
    "multiNB_y_pred = mb_tvec_gs.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Purpose of code: We want to compare the performance of two classifiers so use f1_score. Ultimately, this means, when model predicts, how often is it correct.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score: 0.960656\n",
      "F1 score: 0.937815\n"
     ]
    }
   ],
   "source": [
    "# Print f1_score: 2 TP / (2 TP + FP + FN)\n",
    "f1_logr = f1_score(y_test, logr_y_pred)\n",
    "print('F1 score: %f' % f1_logr)\n",
    "\n",
    "f1_multiNB = f1_score(y_test, multiNB_y_pred)\n",
    "print('F1 score: %f' % f1_multiNB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observations: Great! The F1 scores are high and means precision and recall of model indicates good results. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Purpose of code: It's important to check out the number of correct predictions over total number of predictions (aka Accuracy). This will note how often model is predicting correctly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.960\n",
      "Train score: 0.981\n",
      "Test score: 0.960\n"
     ]
    }
   ],
   "source": [
    "# Print accuracy score for LogisticRegression\n",
    "lr_tvec_score = accuracy_score(y_test, logr_y_pred)\n",
    "# Accuracy= (TP + TN) / all\n",
    "print(\"Accuracy: {:.3f}\".format(lr_tvec_score))\n",
    "# Print best score train set\n",
    "print(\"Train score: {:.3f}\".format(lr_tvec_gs.score(X_train, y_train)))\n",
    "# Print best score test set\n",
    "print(\"Test score: {:.3f}\".format(lr_tvec_gs.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observations: Ooo cool! Model is correctly predicting 96%. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best cross-validation score: 0.981\n"
     ]
    }
   ],
   "source": [
    "# Scoring train data on LogisticRegression\n",
    "logr_train_score = lr_tvec_gs.score(X_train, y_train)\n",
    "print(\"Best cross-validation score: {:.3f}\".format(lr_tvec_gs.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "[[282  17]\n",
      " [  7 293]]\n",
      "\n",
      "---------------\n",
      "[['TN' 'FP']\n",
      " ['FN' 'TP']]\n"
     ]
    }
   ],
   "source": [
    "# Print confusion matrix for Logistic Regression model\n",
    "lr_tvec_cfm = confusion_matrix(y_test, logr_y_pred)\n",
    "print(\"Confusion matrix:\")\n",
    "print(lr_tvec_cfm, end='\\n\\n')\n",
    "print('-'*15)\n",
    "# Print [True Negative, False Positive] [False Negative, True Positive]\n",
    "print(np.array([['TN', 'FP'],[ 'FN' , 'TP']]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observations: Wow! Looks like False Positives and False Negatives are  pretty low which is good in further reaffirming and visually cementing that model is great at predicting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Purpose of code: It's important to check out the number of correct predictions over total number of predictions (aka Accuracy). This will note how many times model is predicting correctly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.938\n",
      "Train score: 0.971\n",
      "Test score: 0.938\n"
     ]
    }
   ],
   "source": [
    "# Print accuracy score for MultinomialNB\n",
    "mb_tvec_score = accuracy_score(y_test, multiNB_y_pred)\n",
    "# Accuracy= (TP + TN) / all\n",
    "print(\"Accuracy: {:.3f}\".format(mb_tvec_score))\n",
    "# Print best score train set\n",
    "print(\"Train score: {:.3f}\".format(mb_tvec_gs.score(X_train, y_train)))\n",
    "# Print best score test set\n",
    "print(\"Test score: {:.3f}\".format(mb_tvec_gs.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observations: Nice! Not the best, but it's solid. 93% correctly predicting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best cross-validation score: 0.971\n"
     ]
    }
   ],
   "source": [
    "# Score for test data on MultinomialNB\n",
    "print(\"Best cross-validation score: {:.3f}\".format(mb_tvec_gs.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "[[283  16]\n",
      " [ 21 279]]\n",
      "\n",
      "---------------\n",
      "[['TN' 'FP']\n",
      " ['FN' 'TP']]\n"
     ]
    }
   ],
   "source": [
    "# Print confusion matrix for MultinomialNB model\n",
    "mb_tvec_cfm = confusion_matrix(y_test, multiNB_y_pred)\n",
    "print(\"Confusion matrix:\")\n",
    "print(mb_tvec_cfm, end='\\n\\n')\n",
    "print('-'*15)\n",
    "# Print [True Negative, False Positive] [False Negative, True Positive]\n",
    "print(np.array([['TN', 'FP'],[ 'FN' , 'TP']]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observations: False Positives and False Negatives are low which is great in further reaffirming and visually cementing that model is great at predicting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After comparing the performance of the Logistic Regression and Multinomial Naive Bayes models, and applying CountVectorizer as well as TfidfVectorizer, <b>Logistic Regression with TfdifVectorizer is the optimal model</b> to use in predicting whether a post goes into subreddit r/Dreams or r/schizophrenia. The optimal model reached a final accuracy score of 96%.\n",
    "\n",
    "While the Multinomial Naive Bayes model did fairly well with both CountVectorizer and TfidfVectorizer as the results were not vastly far from the Logistic Regression models, because it assumes every feature is independent from one another (though not every feature is always independent from one another), perhaps this was the reason for it having a lower score. At the very least, the Multinomial Naive Bayes model is often a great initial baseline to interpret data and assess the next call to actions.  \n",
    "\n",
    "Overall, results were fantastic! This means the models chosen to experiment with were relevant and trained well in producing outputs that can classify the distinctions between the two subreddits. \n",
    "\n",
    "Possible next steps for this project include:\n",
    "<br>\n",
    "- Sentiment Analysis (i.e. looking into phrases, idioms, etc)\n",
    "- Try out other models\n",
    "- Look into other similar subreddits to scrape more text for analysis "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "322.594px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
